{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from ipyleaflet import Map, ImageOverlay, Polyline\n",
    "import matplotlib\n",
    "import matplotlib.cm\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions\n",
    "import scipy\n",
    "import scipy.interpolate\n",
    "import pandas\n",
    "import platypus.io.logs\n",
    "import os\n",
    "import uuid\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES2 sensor is present. Trimming all data within EC = 0 time windows\n",
      "\n",
      "Available sensors/channels:\n",
      "  ES2, ec\n",
      "  ES2, temperature\n"
     ]
    }
   ],
   "source": [
    "# Import the data from the specified logfile\n",
    "log_path = \"/home/jason/Documents/INTCATCH/phone logs/fishing pond/2017-10-12/\"\n",
    "log_filenames = [log_path + \"platypus_20171012_072334.txt\"]\n",
    "csv_output_filename = \"2017_10_12__Atlantide\"\n",
    "log_ext = \".txt\"\n",
    "\n",
    "#data = platypus.io.logs.load(log_path + log_filename + log_ext)\n",
    "data = platypus.io.logs.merge_files(log_filenames)\n",
    "\n",
    "if \"ES2\" in data:\n",
    "    print \"ES2 sensor is present. Trimming all data within EC = 0 time windows\\n\"\n",
    "    # find all time windows where EC is exactly 0\n",
    "    ES2_data = data[\"ES2\"]\n",
    "    values = ES2_data[\"ec\"].values\n",
    "    #ec_eq_zero_indices = np.where(values == 0)[0]\n",
    "    ec_eq_zero_indices = np.where(values < 200)[0]\n",
    "    windows = list()\n",
    "    windows.append([ec_eq_zero_indices[0]])\n",
    "    left = ec_eq_zero_indices[0]\n",
    "    for ii in range(1, ec_eq_zero_indices.shape[0]):\n",
    "        i = ec_eq_zero_indices[ii]\n",
    "        if i - left > 5:\n",
    "            # there has been a jump in index, a new time window has started\n",
    "            windows[-1].append(left)\n",
    "            windows.append([i])\n",
    "        left = i\n",
    "    windows[-1].append(ec_eq_zero_indices[-1])\n",
    "    # print ec_eq_zero_indices\n",
    "    # print windows\n",
    "    for window in windows:\n",
    "        time_window = [ES2_data[\"ec\"].index.values[window[0]], ES2_data[\"ec\"].index.values[window[1]]]\n",
    "        for k in data:\n",
    "            data[k] = data[k].loc[np.logical_or(data[k].index < time_window[0], data[k].index > time_window[1])]\n",
    "else:\n",
    "    print \"No ES2 sensor present. No trimming will be performed.\"\n",
    "    \n",
    "\"\"\"\n",
    "if \"ATLAS_PH\" in data:\n",
    "    print \"pH sensor is present. Trimming all data within pH < 6 time windows\\n\"\n",
    "    # find all time windows where pH is less than 6\n",
    "    pH_data = data[\"ATLAS_PH\"]\n",
    "    values = pH_data[\"ph\"].values\n",
    "    pH_lt_6_indices = np.where(values < 6)[0]\n",
    "    windows = list()\n",
    "    windows.append([pH_lt_6_indices[0]])\n",
    "    left = pH_lt_6_indices[0]\n",
    "    for ii in range(1, pH_lt_6_indices.shape[0]):\n",
    "        i = pH_lt_6_indices[ii]\n",
    "        if i - left > 5:\n",
    "            windows[-1].append(left)\n",
    "            windows.append([i])\n",
    "        left = i\n",
    "    windows[-1].append(pH_lt_6_indices[-1])\n",
    "    for window in windows:\n",
    "        time_window = [pH_data[\"ph\"].index.values[window[0]], pH_data[\"ph\"].index.values[window[1]]]\n",
    "        for k in data:\n",
    "            data[k] = data[k].loc[np.logical_or(data[k].index < time_window[0], data[k].index > time_window[1])]\n",
    "\"\"\"\n",
    "\n",
    "# Define useful access variables.\n",
    "pose = data['pose']\n",
    "position = pose[['latitude', 'longitude']]\n",
    "\n",
    "# Print the available sensors and channels for this logfile.\n",
    "print \"Available sensors/channels:\"\n",
    "for s in data.keys():\n",
    "    if s == 'pose' or s == 'BATTERY':\n",
    "        continue\n",
    "    for c in data[s].dtypes.keys():\n",
    "        print \"  {:s}, {:s}\".format(s, str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select the sensor and the name of the channel for that sensor.\n",
    "sensor_name = 'ES2'\n",
    "sensor_channel = 'ec'\n",
    "sensor_units = 'Electrical Conductivity (uS/cm)'\n",
    "#sensor_units = 'Temperature (C)'\n",
    "#sensor_units = 'Dissolved Oxygen (mg/L)'\n",
    "#sensor_units = \"pH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the pose timing and the sensor data of interest.\n",
    "pose_times = pose.index.values.astype(np.float64)\n",
    "\n",
    "if sensor_name in data:\n",
    "    sensor = data[sensor_name]\n",
    "    sensor_times = sensor.index.values.astype(np.float64)\n",
    "\n",
    "    # Linearly interpolate the position of the sensor at every sample.\n",
    "    sensor_pose_interpolator = scipy.interpolate.interp1d(pose_times, position,\n",
    "                                                          axis=0, bounds_error=False)\n",
    "\n",
    "    # Add the position information back to the sensor data.\n",
    "    sensor = sensor.join(pandas.DataFrame(sensor_pose_interpolator(sensor_times), sensor.index,\n",
    "                                          columns=('latitude', 'longitude')))\n",
    "    \n",
    "    # print sensor data to csv file\n",
    "    sensor.to_csv(log_path + csv_output_filename + \"__\" + sensor_name + \".csv\")\n",
    "\n",
    "    # Remove columns that have NaN values (no pose information).\n",
    "    sensor_valid = np.all(np.isfinite(sensor), axis=1)\n",
    "    sensor = sensor[sensor_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a trail of the vehicle's path on the map.\n",
    "pl = Polyline(locations=position.as_matrix().tolist())\n",
    "pl.fill_opacity = 0.0\n",
    "pl.weight = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    }
   ],
   "source": [
    "# Add a data overlay for the map\n",
    "data_padding = [0.0001, 0.0001]   # degrees lat/lon\n",
    "data_resolution = [0.00001, 0.00001] # degrees lat/lon\n",
    "data_interpolation_radius = 0.00005 # degrees lat/lon\n",
    "data_bounds = [(position.min() - data_padding).tolist(),\n",
    "               (position.max() + data_padding).tolist()]\n",
    "\n",
    "# Create a rectangular grid of overlay points.\n",
    "data_xv, data_yv = np.meshgrid(\n",
    "    np.arange(data_bounds[1][0], data_bounds[0][0], -data_resolution[0]),\n",
    "    np.arange(data_bounds[0][1], data_bounds[1][1], data_resolution[1])\n",
    ")\n",
    "data_shape = data_xv.shape\n",
    "data_xy = np.vstack([data_xv.ravel(), data_yv.ravel()]).T\n",
    "\n",
    "if sensor_name in data:\n",
    "    # Create a radial-basis interpolator over the sensor dataset\n",
    "    # Then, query it at each point of the rectangular grid.\n",
    "    #from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "    #data_estimator = RadiusNeighborsClassifier(radius=data_interpolation_radius, outlier_label=np.nan)\n",
    "    from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "    data_estimator = RadiusNeighborsRegressor(radius=data_interpolation_radius)\n",
    "\n",
    "    data_estimator.fit(sensor[['latitude','longitude']], sensor[sensor_channel].astype(np.float))\n",
    "    data_zv = data_estimator.predict(data_xy)\n",
    "    data_zv = data_zv.reshape(data_shape).T\n",
    "\n",
    "    # Normalize data from [0, 1)\n",
    "    data_max = data_zv[np.isfinite(data_zv)].max()\n",
    "    data_min = data_zv[np.isfinite(data_zv)].min()\n",
    "    print \"Data min = {:f}   Data max = {:f}\".format(data_min, data_max)\n",
    "    NORMALIZER = data_max # 800\n",
    "    data_zv = (data_zv - data_min) / (NORMALIZER - data_min)\n",
    "\n",
    "    # Update a color map only at the points that have valid values.\n",
    "    data_rgb = np.zeros((data_shape[0], data_shape[1], 4), dtype=np.uint8)\n",
    "    data_rgb = matplotlib.cm.jet(data_zv)*255.0\n",
    "    data_rgb[:,:,3] = 255 * np.isfinite(data_zv)\n",
    "\n",
    "    # Remove any old image files.\n",
    "    old_png_files = glob.glob('./*.png')\n",
    "    for old_png_file in old_png_files:\n",
    "        os.remove(old_png_file)\n",
    "\n",
    "    png_filename = './platypus_data_{:s}.png'.format(uuid.uuid4())\n",
    "    scipy.misc.imsave(png_filename, data_rgb)\n",
    "\n",
    "    # Create image overlay that references generated image.\n",
    "    io = ImageOverlay(url=png_filename, bounds=data_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a map centered on this data log.\n",
    "center = [pose['latitude'].median(), pose['longitude'].median()]\n",
    "# print center\n",
    "zoom = 17\n",
    "m = Map(center=center, zoom=zoom, height='1000px')\n",
    "if sensor_name in data:\n",
    "    m += io # Add image overlay\n",
    "if sensor_name not in data:\n",
    "    m += pl # Add vehicle trail, but only if there isn't heatmap data to look at\n",
    "\n",
    "# Make a figure and axes with dimensions as desired.\n",
    "fig = pyplot.figure(figsize=(15, 3))\n",
    "ax1 = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n",
    "\n",
    "if sensor_name in data:\n",
    "    # Set the colormap and norm to correspond to the data for which\n",
    "    # the colorbar will be used.        \n",
    "    cmap = matplotlib.cm.jet\n",
    "    norm = matplotlib.colors.Normalize(vmin=data_min, vmax=NORMALIZER)\n",
    "    cb1 = matplotlib.colorbar.ColorbarBase(ax1, cmap=cmap,\n",
    "                                           norm=norm,\n",
    "                                           orientation='horizontal')\n",
    "    cb1.set_label(sensor_units)\n",
    "\n",
    "pyplot.show()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "353ccbbc0ff94b5bbe0afcc012b3fd5c": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
